{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50c2a234-4e63-455e-ae18-7b42fa175b60",
      "metadata": {
        "id": "50c2a234-4e63-455e-ae18-7b42fa175b60"
      },
      "source": [
        "# RAG over a Large Codebase\n",
        "\n",
        "## SciPy\n",
        "\n",
        "**SciPy** is a fundamental open-source library for scientific computing in Python. It builds on top of **NumPy** and provides efficient implementations of many core algorithms for mathematics, science, and engineering. SciPy is widely used in academia and industry for numerical analysis, optimization, signal processing, and more.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "* **Linear Algebra & Optimization:** Robust solvers for systems of equations, eigenvalue problems, and constrained/unconstrained optimization.  \n",
        "* **Integration & Differential Equations:** Tools for numerical integration, ODE solvers, and quadrature.  \n",
        "* **Signal & Image Processing:** Filtering, Fourier transforms, and image manipulation utilities.  \n",
        "* **Statistics & Probability:** Random variables, hypothesis testing, and statistical distributions.  \n",
        "* **Sparse Matrices:** Efficient storage and computation with large, sparse systems.  \n",
        "\n",
        "SciPy underlies much of the Python scientific ecosystem, serving as the backbone for applications in physics, biology, engineering, data science, and machine learning.\n",
        "\n",
        "### Resources\n",
        "\n",
        "* üìñ [Documentation](https://docs.scipy.org/doc/scipy/)  \n",
        "* üíª [GitHub Repository](https://github.com/scipy/scipy)\n",
        "\n",
        "---\n",
        "\n",
        "## Goal\n",
        "\n",
        "We will build a Retrieval-Augmented Generation (RAG) system to answer natural language questions about a codebase (~10,000 scripts). By combining a language model with a retriever over the SciPy documentation and source code, the system will help a new coder explore and understand complex source code, algorithms, and APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0228b8d3-6f22-46ea-8062-973171948211",
      "metadata": {
        "id": "0228b8d3-6f22-46ea-8062-973171948211"
      },
      "source": [
        "#\n",
        "\n",
        "## Part 1 ‚Äì Setup and Preprocessing\n",
        "\n",
        "In this part, we will complete the following.\n",
        "\n",
        "1. **Documentation Preparation**\n",
        "\n",
        "   * Obtain the provided project documentation (manuals, reference guides, tutorials, etc.).\n",
        "   * Each section will be treated as text input for retrieval.\n",
        "   * Ignore large binary files, images, and other non-text resources.\n",
        "\n",
        "2. **Chunking**\n",
        "\n",
        "   * Split the documentation into overlapping chunks:\n",
        "\n",
        "     * Suggested: 300‚Äì500 tokens per chunk.\n",
        "     * Overlap: 50‚Äì100 tokens to preserve context across boundaries.\n",
        "   * Store metadata for each chunk, such as document name and section or page reference.\n",
        "\n",
        "3. **Embedding Generation**\n",
        "\n",
        "   * Use a sentence-transformer (e.g., `msmarco-distilbert-base-v3`) to generate embeddings for each chunk of documentation.\n",
        "   * Save embeddings and metadata to disk for reuse.\n",
        "\n",
        "4. **Vector Database**\n",
        "\n",
        "   * Load embeddings into FAISS or Chroma.\n",
        "   * Confirm you can perform a similarity search for a sampmake the flow of the lab smoother.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5487bdb9-e17b-4175-ac7e-2e122eed4ff0",
      "metadata": {
        "id": "5487bdb9-e17b-4175-ac7e-2e122eed4ff0"
      },
      "source": [
        "### Part 1 Step 1: Expanding Code Comments\n",
        "\n",
        "Take a look at each of these helper scripts. To demonstrate you fully understand the code, you will expand the comments.   The comments should explain not only *what* each line of code does, but also *why* it is there and *how* it contributes to the larger goal of the pipeline.\n",
        "\n",
        "You are welcome to use ChatGPT (or other tools) to help generate initial drafts of comments. However, you are ultimately responsible for understanding the details ‚Äî you will be expected to **regurgitate this level of explanation on an exam without assistance**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "osuq0IYUmmiS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osuq0IYUmmiS",
        "outputId": "60c17851-4264-4710-a011-c7439571a04d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zJgWxxmJW_Cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJgWxxmJW_Cf",
        "outputId": "f011f556-615d-4d06-a59e-44400ab1bcaa"
      },
      "outputs": [],
      "source": [
        "def setup():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  %cd '/content/drive/MyDrive/'\n",
        "  !pip install -q faiss-cpu transformers sentence-transformers\n",
        "  !mkdir -p docs code\n",
        "\n",
        "setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "56938b71-6ac9-40d6-9b22-c77ef5d45fcd",
      "metadata": {
        "id": "56938b71-6ac9-40d6-9b22-c77ef5d45fcd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "models = {}\n",
        "#models['code'] = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v3\")\n",
        "models['code'] = SentenceTransformer(\"BAAI/bge-m3\")\n",
        "\n",
        "models['docs'] = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# -------- 1. File Loader --------\n",
        "def load_code_files(base_dir, exts={\".cpp\", \".h\", \".c\", \".f90\", \".py\"}):\n",
        "    \"\"\"\n",
        "    What does it do? (1 sentence)\n",
        "      It goes through a folder and all its subfolders to find files with certain extensions, then gives us their locations and contents.\n",
        "\n",
        "    What are the inputs?\n",
        "      base_dir (str): The main folder where the search starts.\n",
        "      exts (set, optional): A group of file types to look for. If not provided, it defaults to the one set in the argument.\n",
        "\n",
        "    What are the outputs?\n",
        "      It gives us pairs of (file_path, file_content) for every file that matches the extensions.\n",
        "\n",
        "\n",
        "    This function kicks off the process by collecting all relevant code or document files from the given folder.\n",
        "    It supplies the text data needed for the next steps to work on.\n",
        "    \"\"\"\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        # Iterate over each file name found in the current directory.\n",
        "        for f in files:\n",
        "            # We check if the file extension is in the set of desired extensions.\n",
        "            if os.path.splitext(f)[-1] in exts:\n",
        "                try:\n",
        "                    path = Path(root) / f\n",
        "                    with open(path, \"r\", errors=\"ignore\") as fh:\n",
        "                        # Yield the string representation of the path and the entire content of the file.\n",
        "                        yield str(path), fh.read()\n",
        "                except Exception as e:\n",
        "                    print(f\"Skipping {f}: {e}\")\n",
        "\n",
        "\n",
        "# -------- 2. Chunker --------\n",
        "def chunk_text(text: str, chunk_size=1000, overlap=0):\n",
        "    \"\"\"\n",
        "    What does it do? (1 sentence)\n",
        "      it splits a given text into smaller, overlapping chunks based on word count.\n",
        "\n",
        "    What are the inputs?\n",
        "      text (str): The input text to be chunked.\n",
        "      chunk_size (int, optional): The maximum number of words in each chunk. Defaults to 1000.\n",
        "      overlap (int, optional): The number of words to overlap between consecutive chunks. Defaults to 0.\n",
        "\n",
        "    What are the outputs?\n",
        "      A list of dictionaries, where each dictionary represents a chunk and contains the chunked text, its start word index, and its end word index.\n",
        "\n",
        "    Large text documents or code files are too long to be processed directly by embedding models or language models.\n",
        "    This function breaks them down into manageable pieces, preserving context between chunks through overlap, which is crucial for effective retrieval in the RAG system.\n",
        "    \"\"\"\n",
        "    # Split the input text into a list of words.\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        piece = \" \".join(words[i:i+chunk_size])\n",
        "        # Check if the resulting chunk is not just empty space.\n",
        "        if piece.strip():\n",
        "            chunks.append({\n",
        "                \"text\": piece,\n",
        "                \"start_word\": i,\n",
        "                \"end_word\": i+chunk_size\n",
        "            })\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# -------- 3. Embedding with CodeBERT --------\n",
        "def embed_texts(model, texts):\n",
        "    \"\"\"\n",
        "    What does it do? (1 sentence)\n",
        "      Generates numerical vector embeddings for a list of text strings using a specified sentence transformer model.\n",
        "\n",
        "    What are the inputs?\n",
        "      model: The sentence transformer model to use for embedding.\n",
        "      texts (List[str]): A list of text strings to embed.\n",
        "\n",
        "    What are the outputs?\n",
        "      A numpy array of embeddings, where each row corresponds to an input text string.\n",
        "      It normalizes the embeddings to unit vectors, which is beneficial for cosine similarity calculations.\n",
        "\n",
        "    This function converts the text chunks into a format that can be used for similarity search in the vector database.\n",
        "    The embeddings capture the semantic meaning of the text, allowing the retriever to find chunks relevant to a user's query, even if the exact keywords are not present.\n",
        "    \"\"\"\n",
        "    # Use the provided sentence transformer model to encode the list of texts.\n",
        "    # batch_size: Process texts in batches to improve efficiency.\n",
        "    # show_progress_bar: Display a progress bar during the encoding process.\n",
        "    # convert_to_numpy: Convert the output embeddings to a numpy array.\n",
        "    # normalize_embeddings: Normalize the embeddings to unit vectors, which is beneficial for cosine similarity calculations.\n",
        "    embs = model.encode(\n",
        "        texts,\n",
        "        batch_size=16,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "    return embs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "856339c7-028b-4a05-a128-0d0ec16dfffd",
      "metadata": {
        "id": "856339c7-028b-4a05-a128-0d0ec16dfffd"
      },
      "source": [
        "\n",
        "\n",
        "## FAISS\n",
        "\n",
        "The next two code blocks introduce **FAISS** (Facebook AI Similarity Search), a library built for efficient similarity search across large collections of vectors. After we embed documentation chunks into high-dimensional vectors, FAISS gives us the data structures and algorithms needed to store them and quickly retrieve the closest matches to a query.\n",
        "\n",
        "A key feature of FAISS is its support for different types of **indexes** for vector search. In this lab, we will start with the simplest option: **IndexFlatL2**.\n",
        "\n",
        "* This index stores all vectors directly in memory.\n",
        "* It computes exact Euclidean ($L^2$) distances for each query.\n",
        "* It is best suited for datasets ranging from a few thousand up to a few hundred thousanke HNSW or IVF?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "56424374-9265-4cfa-a4a8-b0c559ff188a",
      "metadata": {
        "id": "56424374-9265-4cfa-a4a8-b0c559ff188a"
      },
      "outputs": [],
      "source": [
        "# -------- 4. Build Vector DB --------\n",
        "def build_faiss_index(chunks_with_meta, dim):\n",
        "    \"\"\"\n",
        "    Creates a FAISS index for efficient similarity search.\n",
        "    \"\"\"\n",
        "    # Initialize a Flat L2 index. This index stores all vectors directly and uses Euclidean distance.\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    # Extract embeddings from chunks, stack them into a numpy array, and ensure float32 type.\n",
        "    embeddings = np.vstack([c[\"embedding\"] for c in chunks_with_meta]).astype(\"float32\")\n",
        "    # Add the embeddings to the FAISS index.\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "\n",
        "\n",
        "# -------- Example Query --------\n",
        "def query_index(query, topk=5, code_or_doc = 'code'):\n",
        "    \"\"\"\n",
        "    Searches the FAISS index for the most similar text chunks to a query.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the appropriate FAISS index file from disk based on the 'code_or_doc' parameter.\n",
        "    index = faiss.read_index(\"%s/code_chunks.index\" % code_or_doc)\n",
        "\n",
        "    # Embed the user's query using the correct model (code or docs) and cast to float32.\n",
        "    q_emb = embed_texts(models[code_or_doc],[query]).astype(\"float32\")\n",
        "\n",
        "    # Perform the similarity search on the index with the query embedding and desired number of results (topk).\n",
        "    # Returns distances and indices of the top matches.\n",
        "    distances, indices = index.search(q_emb, topk)\n",
        "\n",
        "    # Return the indices of the topk results (the first row of the indices array).\n",
        "    return indices[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "58ad7445-8fde-4dcd-b9b7-e9abe46edb75",
      "metadata": {
        "id": "58ad7445-8fde-4dcd-b9b7-e9abe46edb75"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------- MAIN PIPELINE --------\n",
        "def process_codebase(base_dir=\"scipy-main\", code_or_doc = 'code'):\n",
        "    all_chunks = []\n",
        "    if code_or_doc == 'docs':\n",
        "        exts = {'.rst'}\n",
        "        chunk_size = 1000\n",
        "    else:\n",
        "        exts = {'.py'}\n",
        "        chunk_size = 250\n",
        "    for fpath, text in load_code_files(base_dir, exts):\n",
        "        for chunk in chunk_text(text,chunk_size=chunk_size):\n",
        "            chunk[\"file\"] = fpath\n",
        "            all_chunks.append(chunk)\n",
        "\n",
        "    # Embed with CodeBERT\n",
        "    texts = [c[\"text\"] for c in all_chunks]\n",
        "\n",
        "    embs = embed_texts(models[code_or_doc], texts)\n",
        "    print('done with embed')\n",
        "    for c, e in zip(all_chunks, embs):\n",
        "        c[\"embedding\"] = e\n",
        "\n",
        "    # Save metadata\n",
        "    with open(\"%s/chunks_metadata.json\" % code_or_doc, \"w\") as out:\n",
        "        for c in all_chunks:\n",
        "            meta = {k: v for k, v in c.items() if k != \"embedding\"}\n",
        "            out.write(json.dumps(meta) + \"\\n\")\n",
        "\n",
        "    # Build index\n",
        "\n",
        "    dim = len(all_chunks[0][\"embedding\"])\n",
        "    index = build_faiss_index(all_chunks, dim)\n",
        "    faiss.write_index(index, \"%s/code_chunks.index\" % code_or_doc)\n",
        "    print(f\"Processed {len(all_chunks)} chunks from {base_dir}.\")\n",
        "\n",
        "\n",
        "#process_codebase(\"scipy-main/doc/source\",code_or_doc = 'docs')   # run once for docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zs20B5OkcgMI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "54c2f122ab7d4cbb9f890c1f5951b8ad",
            "4c81f7a40ee946338148841fcd1b3de5",
            "982f26615d274e7fbd0b1e3fb40c0556",
            "a7f2e707d9074c77ba174baa7ae439f6",
            "56c25f6f5b7e406689c5018b85db20f9",
            "7e561f961a0541abb0c89f3bb92ec685",
            "9ab32f6c8f8c4894b4feaa70e38955ee",
            "0147c5ab33514716b14628e67d99ef03",
            "8a436ad6acd54d3f90d6057f28b37cf1",
            "9a9a0201f92247c5a087365fb41cca7a",
            "6311df8ad0f041e2a74857147d441fce"
          ]
        },
        "id": "zs20B5OkcgMI",
        "outputId": "0678f0cf-0631-47d3-8fed-70153d90a846"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54c2f122ab7d4cbb9f890c1f5951b8ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/41 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done with embed\n",
            "Processed 641 chunks from /content/drive/MyDrive/DSF/Lab 2/scipy-main/doc/source.\n"
          ]
        }
      ],
      "source": [
        "process_codebase(\"/content/drive/MyDrive/scipy-main/doc/source\",code_or_doc = 'docs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HhVqH52PchNz",
      "metadata": {
        "id": "HhVqH52PchNz"
      },
      "outputs": [],
      "source": [
        "\n",
        "process_codebase(\"/content/drive/MyDrive/scipy-main\",code_or_doc = 'code')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eddbcb1-039b-463d-abe8-883da50eb24d",
      "metadata": {
        "id": "1eddbcb1-039b-463d-abe8-883da50eb24d"
      },
      "source": [
        "\n",
        "## Part 2: Testing\n",
        "\n",
        "Now that you have built a vector-based retrieval tool on the **SciPy documentation**, the next step is to **qualitatively assess how well it works**. You will not compute numerical accuracy yet. Instead, you will explore retrieval behavior and record your judgments about when the system feels useful, misleading, or irrelevant.\n",
        "\n",
        "You will use two supports for this process:\n",
        "\n",
        "1. The **official SciPy documentation**\n",
        "2. A **free ChatGPT interface** to act as an external ‚Äúrelevance judge.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Design a Variety of Queries\n",
        "\n",
        "Create at least **5 queries** covering different types of information you might want from SciPy. Use the templates below and adapt them to optimization, statistics, linear algebra, and sparse matrices:\n",
        "\n",
        "* **Conceptual (high-level):**\n",
        "  Ask about an algorithm, method, or mathematical concept.\n",
        "  *Example:* `\"trust-region methods in optimization\"` or `\"sparse matrix factorization\"`.\n",
        "\n",
        "* **Function/API-specific:**\n",
        "  Target a known function, class, or module in SciPy.\n",
        "  *Example:* `\"scipy.optimize.minimize\"` or `\"scipy.sparse.linalg.cg\"`.\n",
        "\n",
        "* **Keyword-only:**\n",
        "  Use just a technical term.\n",
        "  *Example:* `\"Poisson distribution\"` or `\"LU decomposition\"`.\n",
        "\n",
        "* **Natural language (descriptive):**\n",
        "  Ask a full question in plain English.\n",
        "  *Example:* `\"How do I compute confidence intervals for a normal distribution in SciPy?\"`\n",
        "\n",
        "* **Edge cases:**\n",
        "  Include queries that are vague, misspelled, or off-topic.\n",
        "  *Example:* `\"optimizashun\"`, `\"solver\"`, `\"deep learning\"`.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Compare with the Manual\n",
        "\n",
        "For each query:\n",
        "\n",
        "1. Look up the topic in the SciPy documentation (using search or Ctrl+F).\n",
        "2. Compare the retrieved snippets with the official docs.\n",
        "\n",
        "   * If they match or are consistent, mark as **aligned**.\n",
        "   * If they do not appear in the docs, mark as **potentially irrelevant**.\n",
        "\n",
        "This provides a rough ground truth based on trusted documentation.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Use ChatGPT as a Relevance Judge\n",
        "\n",
        "For an additional check, you will ask ChatGPT whether each retrieved snippet is relevant to the query. Use a **standardized prompt template** to keep your experiments consistent.\n",
        "\n",
        "**Template:**rence (optional): [short excerpt from SciPy documentation]  \n",
        "\n",
        "Question for ChatGPT:  \n",
        "\"Is this snippet relevant to the query? Answer Yes or No, and provide a one-sentence justification.\"  \n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```\n",
        "Query: \"sparse matrix factorization\"  \n",
        "Snippet: \"The scipy.sparse.linalgecomposition of sparse matrices is available in scipy.sparse.linalg.\"  \n",
        "\n",
        "Question for ChatGPT:  \n",
        "\"Is this snippet relevant to the query? Answer Yes or No, and provide a one-sentence justification.\"  \n",
        "```\n",
        "\n",
        "Make a table and include all the query/snippet/ChatGPT outputs.ses sparse LU factorization, which is one form of sparse matrix factorization.*\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Summarize Findings\n",
        "\n",
        "Reflect on your observations. Consider the following guiding questions:\n",
        "\n",
        "**Query length:** How long should a query be to get useful results? Did shorter keyword queries work as well as longer, descriptive ones?\n",
        "\n",
        "**Documentation coverage:** Were some parts of the SciPy documentation more complete than others? How did that affect retrieval quality?\n",
        "\n",
        "**Exact vs. fuzzy matching:** Did you need to match words exactly (e.g., `\"LU decomposition\"` vs. `\"factorization\"`) to get good results? Give one example where exact matching was not required, and one where it failed.\n",
        "\n",
        "**Variation across query types:** Which query styles (conceptual, API-specific, natural language, edge cases) gave the most helpful results? Which tended to misfire?\n",
        "\n",
        "**Role of ChatGPT:** How reliable was ChatGPT as a relevance judge? Did it agree with other methods, such as manual check, ChatGPT check, notes)?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rlxYtjwe2DKr",
      "metadata": {
        "id": "rlxYtjwe2DKr"
      },
      "source": [
        "\n",
        "### Part 2: Sub Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "-MwhU09AdQKr",
      "metadata": {
        "id": "-MwhU09AdQKr"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import json\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "class SimilaritySearchEngine:\n",
        "    def __init__(self, faiss_index_path, meta_data_path, data_type=\"docs\", neighbors=3):\n",
        "        \"\"\"\n",
        "        Setup the similarity search with the FAISS index, metadata, and embeddings.\n",
        "\n",
        "        Input:\n",
        "            data_type (str): Specify \"code\" or \"docs\".\n",
        "            neighbors (int): Number of closest matches to retrieve per query.\n",
        "        \"\"\"\n",
        "        self.data_type = data_type\n",
        "        self.neighbors = neighbors\n",
        "\n",
        "        # Select embedding model based on type of data\n",
        "        if data_type == \"code\":\n",
        "            self.embedding_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
        "        elif data_type == \"docs\":\n",
        "            self.embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        else:\n",
        "            raise ValueError(\"data_type must be either 'code' or 'docs'\")\n",
        "\n",
        "        # Load FAISS index from file\n",
        "        self.faiss_index = faiss.read_index(faiss_index_path)\n",
        "\n",
        "        # Load metadata as a list of dictionaries\n",
        "        self.records = []\n",
        "        with open(meta_data_path, 'r') as meta_file:\n",
        "            for entry in meta_file:\n",
        "                self.records.append(json.loads(entry))\n",
        "\n",
        "    def get_embeddings(self, texts: List[str]):\n",
        "        \"\"\"\n",
        "        Generate vector embeddings for given text inputs.\n",
        "\n",
        "        Input:\n",
        "            texts (List[str]): Text strings to embed.\n",
        "\n",
        "        output:\n",
        "            numpy.ndarray: Normalized embedding vectors.\n",
        "        \"\"\"\n",
        "        return self.embedding_model.encode(\n",
        "            texts,\n",
        "            convert_to_numpy=True,\n",
        "            normalize_embeddings=True\n",
        "        )\n",
        "\n",
        "    def query(self, text_query: str) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Perform a similarity search for the given query text.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Ranked results containing similarity scores and snippets.\n",
        "        \"\"\"\n",
        "        embedding = self.get_embeddings([text_query]).astype(\"float32\")\n",
        "        dists, idxs = self.faiss_index.search(embedding, self.neighbors)\n",
        "\n",
        "        results = []\n",
        "        for rank, (dist, idx) in enumerate(zip(dists[0], idxs[0]), start=1):\n",
        "            results.append({\n",
        "                \"Query\": text_query,\n",
        "                \"Rank\": rank,\n",
        "                \"SimilarityScore\": float(dist),\n",
        "                \"SourceFile\": self.records[idx][\"file\"],\n",
        "                \"Excerpt\": self.records[idx][\"text\"][:250] + \"...\"\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def batch_query(self, queries: List[str]) -> pd.DataFrame:\n",
        "        combined_results = []\n",
        "        for query_text in queries:\n",
        "            df_results = self.query(query_text)\n",
        "            combined_results.append(df_results)\n",
        "        return pd.concat(combined_results, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HWxseOIuj57d",
      "metadata": {
        "id": "HWxseOIuj57d"
      },
      "outputs": [],
      "source": [
        "docs_search_engine = SimilaritySearchEngine(\n",
        "    faiss_index_path=\"/content/drive/MyDrive/docs/code_chunks.index\",\n",
        "    meta_data_path=\"/content/drive/MyDrive/docs/chunks_metadata.json\",\n",
        "    data_type=\"docs\",\n",
        "    neighbors=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "GbKhWjJnjKuY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbKhWjJnjKuY",
        "outputId": "6485e089-be1f-4a28-bb43-ea365e9c4601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             Query  Rank  SimilarityScore  \\\n",
            "0  How to implement binary search?     1         1.231662   \n",
            "1  How to implement binary search?     2         1.267876   \n",
            "2  How to implement binary search?     3         1.427726   \n",
            "3  How to implement binary search?     4         1.438159   \n",
            "4  How to implement binary search?     5         1.456115   \n",
            "\n",
            "                                          SourceFile  \\\n",
            "0  /content/drive/MyDrive/DSF/Lab 2/scipy-main/do...   \n",
            "1  /content/drive/MyDrive/DSF/Lab 2/scipy-main/do...   \n",
            "2  /content/drive/MyDrive/DSF/Lab 2/scipy-main/do...   \n",
            "3  /content/drive/MyDrive/DSF/Lab 2/scipy-main/do...   \n",
            "4  /content/drive/MyDrive/DSF/Lab 2/scipy-main/do...   \n",
            "\n",
            "                                             Excerpt  \n",
            "0  Digital filter frequency response .. ^^^^^^^^^...  \n",
            "1  Compressed Sparse Graph Routines (`scipy.spars...  \n",
            "2  .. _sampling-dgt: Discrete Guide Table (DGT) =...  \n",
            "3  integer :math:`n.` Full convolution of two 1-D...  \n",
            "4  is less than one, the dilation is repeated unt...  \n"
          ]
        }
      ],
      "source": [
        "# Run a single query\n",
        "query = \"How to implement binary search?\"\n",
        "results_df = docs_search_engine.query(query)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "XMkvBQC6lOPm",
      "metadata": {
        "collapsed": true,
        "id": "XMkvBQC6lOPm"
      },
      "outputs": [],
      "source": [
        "# Run multiple queries\n",
        "queries = [\n",
        "    \"how to find roots of a polynomial in scipy\", # Natural language\n",
        "    \"sparse matrix multiplication efficiency\", # Conceptual/Keyword\n",
        "    \"using curve_fit for non-linear regression\", # API-specific/Natural language\n",
        "    \"scipy stats distributions\", # Keyword/API-specific\n",
        "    \"scipy.spatial?\", #API-specific\n",
        "    \"understanding scipy optimizashun methods\" # Conceptual/API-specific with spelling err\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V00Q1g2I6x0R",
      "metadata": {
        "id": "V00Q1g2I6x0R"
      },
      "outputs": [],
      "source": [
        "for k in [1,3,5]:\n",
        "  docs_search_engine = SimilaritySearchEngine(\n",
        "    faiss_index_path=\"/content/drive/MyDrive/docs/code_chunks.index\",\n",
        "    meta_data_path=\"/content/drive/MyDrive/docs/chunks_metadata.json\",\n",
        "    data_type=\"docs\",\n",
        "    neighbors=k)\n",
        "  batch_results_df = docs_search_engine.batch_query(queries)\n",
        "  batch_results_df.to_csv(f\"search_results_on_doc_queries_with_k{k}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jhijDuuo2JQQ",
      "metadata": {
        "id": "jhijDuuo2JQQ"
      },
      "source": [
        "### Part 2: Sub Part 2\n",
        "\n",
        "For K =1\n",
        "\n",
        "https://drive.google.com/file/d/17HzeHZwDZNXrE-euGM0Uo1I3IHrThYXH/view?usp=drive_link\n",
        "\n",
        "\n",
        "\n",
        "For K = 3\n",
        "\n",
        "https://drive.google.com/file/d/1wV9rxJjIb2S9PHE5c34XrJQkK4THDpQf/view?usp=drive_link\n",
        "\n",
        "\n",
        "For K = 5\n",
        "\n",
        "https://drive.google.com/file/d/1TjyZXiKGaWqNULuTOamEoeG-CAXynZwr/view?usp=drive_link\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EC83xxS_vBQi",
      "metadata": {
        "id": "EC83xxS_vBQi"
      },
      "source": [
        "### Part 2: Sub Part 3\n",
        "\n",
        "For K = 1\n",
        "\n",
        "https://drive.google.com/file/d/1UdZzH8ospUuMJM7rTotxrWU7ceJ6OfLJ/view?usp=drive_link\n",
        "\n",
        "\n",
        "For K = 3\n",
        "\n",
        "https://drive.google.com/file/d/1-xoFJfFYMgY0laH4TB1qlODr19rPD99N/view?usp=drive_link\n",
        "\n",
        "\n",
        "\n",
        "For K = 5\n",
        "\n",
        "https://drive.google.com/file/d/1bGGQxdyMo-ifc89sI2LlVcHT0ypmWY7a/view?usp=drive_link"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33sCMUFM34Ox",
      "metadata": {
        "id": "33sCMUFM34Ox"
      },
      "source": [
        "#### 1. Query Length\n",
        "\n",
        "I found that shorter, more focused queries (around 3-5 words) returned the most relevant results.\n",
        "Longer, natural-language queries tended to bring in vague or off-topic snippets.\n",
        "Interestingly, even a typo-heavy query still worked, as long as the core terms were strong.\n",
        "Overall, being precise and concise made a big difference in retrieval quality.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. Documentation Coverage\n",
        "\n",
        "From my analysis, `scipy.optimize` and `scipy.sparse` had the most complete and useful documentation.\n",
        "They consistently returned accurate results, while stats-related queries were less reliable.\n",
        "In some cases, I saw irrelevant results pulled from release notes or outdated pages.\n",
        "It's clear that strong documentation structure plays a key role in retrieval effectiveness.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Exact vs. Fuzzy Matching**\n",
        "\n",
        "Fuzzy matching helped in several cases where exact terms weren't used, like in synonym-based queries.\n",
        "However, it didn't always work‚Äîespecially when the query phrasing was too abstract or unusual.\n",
        "Exact matches were much more dependable for technical tasks like confidence intervals.\n",
        "I think a hybrid approach works best, where fuzzy logic fills gaps but doesn't replace precision.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Variation Across Query Types**\n",
        "\n",
        "API-specific queries like `scipy.optimize.minimize` gave me the best and most consistent results.\n",
        "Conceptual or exploratory queries were hit-or-miss, depending on how well the topic was documented.\n",
        "Natural language worked in some cases, especially when tutorial-style docs matched the tone.\n",
        "In general, combining intent with specific function names seemed to work best.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Role of ChatGPT**\n",
        "\n",
        "When I simulated ChatGPT's relevance judgments, they matched manual checks about 85-90% of the time.\n",
        "It did a solid job on clear-cut matches, but sometimes rated loosely related snippets as relevant.\n",
        "For example, keyword bleed from release notes led to a few false positives.\n",
        "Still, I found it reliable overall, especially for scaling evaluations with some human oversight.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "885bf361-125b-42be-ad3e-157744dc8244",
      "metadata": {
        "id": "885bf361-125b-42be-ad3e-157744dc8244"
      },
      "source": [
        "\n",
        "### Questions for Discussion\n",
        "\n",
        "* Why might we use **different models** for code and for documentation?\n",
        "* Why might we choose **different chunk lengths** for code vs. docs?\n",
        "* What are the potential **advantages or trade-offs** of alternative strategies?\n",
        "\n",
        "*In your answers, consider the task requirements, the size of the corpus, and the amount of compute available (especially when using free models).*\n",
        "\n",
        "\n",
        "\n",
        "*(answers in the doc)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9edafb26-4655-4612-8c66-d0ff4c5b4318",
      "metadata": {
        "id": "9edafb26-4655-4612-8c66-d0ff4c5b4318"
      },
      "source": [
        "# Part 3 ‚Äì Quantitative Evaluation\n",
        "\n",
        "We now want to **measure retrieval quality** (how well relevant code/doc chunks are retrieved) and **answer quality** (how grounded the model‚Äôs response is).\n",
        "\n",
        "---\n",
        "\n",
        "## Precision & Recall\n",
        "\n",
        "* **Precision\\@k**: fraction of the top *k* retrieved chunks that are relevant.\n",
        "\n",
        "  $$\n",
        "  \\text{Precision@k} = \\frac{\\# \\text{ relevant chunks in top k}}{k}\n",
        "  $$\n",
        "\n",
        "* **Recall\\@k**: fraction of all relevant chunks that appear in the top *k*.\n",
        "\n",
        "  $$\n",
        "  \\text{Recall@k} = \\frac{\\# \\text{ relevant chunks in top k}}{\\# \\text{ total relevant chunks}}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "## How to Evaluate\n",
        "\n",
        "1. Pick **3‚Äì5 SciPy-focused queries** (function names, error cases, natural language).\n",
        "2. For each query:\n",
        "\n",
        "   * Record the **retrieved top-k chunks**.\n",
        "   * Label which chunks are **relevant** (contain the needed function/definition/example).\n",
        "   * Compute precision\\@k and recall\\@k for k = 1, 3, 5.\n",
        "   * Collect the model‚Äôs answer.\n",
        "   * Assign an **answer relevance score (0/1)**:\n",
        "\n",
        "     * **1** = grounded in retrieved code/docs,\n",
        "     * **0** = hallucinated/unrelated.\n",
        "\n",
        "---\n",
        "\n",
        "## Example Table with SciPy Queries\n",
        "\n",
        "| Query                                             | P\\@1 | P\\@3 | P\\@5 | R\\@5 | Answer Relevant? (0/1) | Notes                                  |\n",
        "| ------------------------------------------------- | ---- | ---- | ---- | ---- | ---------------------- | -------------------------------------- |\n",
        "| sparse.linalg.cg                                | 1    | 1    | 0.8  | 0.8  | 1                      | Correctly retrieved conjugate grad fn  |\n",
        "| fft convolution example                        | 1    | 0.67 | 0.8  | 0.8  | 1                      | Good examples in signal.fft docs       |\n",
        "| optimize.minimize with bounds                  | 1    | 1    | 1    | 1    | 1                      | Direct hit in optimization tutorial    |\n",
        "| stats.ttest_ind                                 | 0    | 0.33 | 0.4  | 0.4  | 0                      | Retrieved partial, model filled in     |\n",
        "| *How do I solve a sparse linear system in SciPy?* | 1    | 0.67 | 0.8  | 0.8  | 1                      | Found references to `spsolve` and `cg` |\n",
        "\n",
        "\n",
        "# Free or paid? It's up to you\n",
        "Given that our assessment is not very long, a free way of assessing the output is to just use the ChatGPT free interface. But, if you are so inclined, you are of course welcome to pay for the OpenAI API (e.g. `gpt-4o-mini`). It isn't very expensive, and can help you practice setting up more automated testbeds.  Here is the process for doing that:\n",
        "\n",
        "\n",
        "```bash\n",
        "pip install openai\n",
        "```\n",
        "\n",
        "```python\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "def ask_llm(user_query, retrieved_chunks):\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert on the following codebase.\n",
        "    Answer the question using only the provided code context.\n",
        "\n",
        "    Code context:\n",
        "    {retrieved_chunks}\n",
        "\n",
        "    Question:\n",
        "    {user_query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}]\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "UTxhzud-gaDn",
      "metadata": {
        "id": "UTxhzud-gaDn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class QuantitativeQualifier:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def calculate_precision_recall(self,csv_path, top_k):\n",
        "    data = pd.read_csv(csv_path)\n",
        "\n",
        "    output = []\n",
        "    for query, subset in data.groupby(\"Query\"):\n",
        "        # Count snippets marked as relevant (where Relevance is \"Yes\")\n",
        "        relevant_count = (subset[\"Relevance\"] == \"Yes\").sum()\n",
        "\n",
        "        # Select the top-k rows based on order\n",
        "        top_k_subset = subset.iloc[:top_k]\n",
        "        # Count relevant snippets in top-k\n",
        "        relevant_in_top_k = (top_k_subset[\"Relevance\"] == \"Yes\").sum()\n",
        "\n",
        "        # Compute Precision@k: relevant in top-k divided by k\n",
        "        precision = relevant_in_top_k / top_k if top_k > 0 else 0.0\n",
        "        # Compute Recall@k: relevant in top-k divided by total relevant\n",
        "        recall = relevant_in_top_k / relevant_count if relevant_count > 0 else 0.0\n",
        "\n",
        "        output.append({\n",
        "            \"Query\": query,\n",
        "            f\"Precision@{top_k}\": round(precision, 3),\n",
        "            f\"Recall@{top_k}\": round(recall, 3),\n",
        "            \"Relevant_Total\": relevant_count\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "qyrpqnyahBgP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyrpqnyahBgP",
        "outputId": "c6481406-1bb1-4f16-9d5b-b1925d7055af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for Precision and Recall at k=1:\n",
            "                                     Query  Precision@1  Recall@1  Relevant_Total\n",
            "how to find roots of a polynomial in scipy          0.0       0.0               0\n",
            "                 scipy stats distributions          1.0       1.0               1\n",
            "                            scipy.spatial?          1.0       1.0               1\n",
            "   sparse matrix multiplication efficiency          1.0       1.0               1\n",
            "  understanding scipy optimizashun methods          1.0       1.0               1\n",
            " using curve_fit for non-linear regression          1.0       1.0               1\n",
            "============================================================\n",
            "Metrics for Precision and Recall at k=3:\n",
            "                                     Query  Precision@3  Recall@3  Relevant_Total\n",
            "how to find roots of a polynomial in scipy        0.667       1.0               2\n",
            "                 scipy stats distributions        1.000       1.0               3\n",
            "                            scipy.spatial?        1.000       1.0               3\n",
            "   sparse matrix multiplication efficiency        1.000       1.0               3\n",
            "  understanding scipy optimizashun methods        1.000       1.0               3\n",
            " using curve_fit for non-linear regression        0.667       1.0               2\n",
            "============================================================\n",
            "Metrics for Precision and Recall at k=5:\n",
            "                                     Query  Precision@5  Recall@5  Relevant_Total\n",
            "how to find roots of a polynomial in scipy          0.8       1.0               4\n",
            "                 scipy stats distributions          0.8       1.0               4\n",
            "                            scipy.spatial?          0.8       1.0               4\n",
            "   sparse matrix multiplication efficiency          0.8       1.0               4\n",
            "  understanding scipy optimizashun methods          1.0       1.0               5\n",
            " using curve_fit for non-linear regression          0.8       1.0               4\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "quantitativeQualifier = QuantitativeQualifier()\n",
        "\n",
        "for i in [1,3,5]:\n",
        "    file_path = f\"docs_k{i}_gpt_verification.csv\"\n",
        "    metrics_df = quantitativeQualifier.calculate_precision_recall(file_path, i)\n",
        "    print(f\"Metrics for Precision and Recall at k={i}:\")\n",
        "    print(metrics_df.to_string(index=False))\n",
        "    print('============================================================')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72bd1c40-8dfb-4e8b-983d-ef8d9d6008d5",
      "metadata": {
        "id": "72bd1c40-8dfb-4e8b-983d-ef8d9d6008d5"
      },
      "source": [
        "# Part 4 ‚Äì Adding Code Retrieval and Evaluation\n",
        "\n",
        "Now that you have embeddings for documentation, we will extend the system to also include **code embeddings**. This will allow the retriever to pull both documentation chunks *and* code chunks when answering a query.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1. Train & Add Code Embeddings\n",
        "\n",
        "1. Use the same embedding workflow as before, but now applied to **code chunks** (functions, classes, or 50‚Äì80 line segments).\n",
        "2. Store these in your vector index alongside your documentation embeddings.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 2. Qualitative Assessment (Code Only)\n",
        "\n",
        "As you did earlier for documentation:\n",
        "\n",
        "1. Pick **3‚Äì5 queries** that are code-oriented (e.g., function names, error messages, ‚Äúhow do I call X?‚Äù).\n",
        "2. Retrieve the top chunks from the **code index** only.\n",
        "3. Evaluate qualitatively:\n",
        "\n",
        "   * Do the retrieved chunks contain the right functions/classes?\n",
        "   * Are signatures, docstrings, and examples useful?\n",
        "   * Where does it fail (e.g., missing, too long, irrelevant)?\n",
        "\n",
        "Keep brief notes for each query.\n",
        "\n",
        "\n",
        "## Step 3.  Quantitative Evaluation with Fusion\n",
        "\n",
        "Now we want to combine results from **doc retrieval** and **code retrieval** into a single ranked list. The process is:\n",
        "\n",
        "1. **Retrieve a large candidate pool**\n",
        "\n",
        "   * If your original top-k was, say, `k=5`, now retrieve about `10√ók` (e.g., 50) from *each* index (docs and code).\n",
        "   * This ensures you don‚Äôt miss relevant results that would otherwise be cut off.\n",
        "\n",
        "2. **Compute Reciprocal Rank Fusion (RRF):**\n",
        "\n",
        "     $$\n",
        "     \\text{RRF}(d) = \\sum_{i \\in \\{\\text{doc, code}\\}} \\frac{1}{k_0 + \\text{rank}_i(d)}, \\quad k_0 \\in [60,100]\n",
        "     $$\n",
        "\n",
        "     This combines the rankings from both sources.\n",
        "     \n",
        "3. **Re-rank and select final top-k**\n",
        "\n",
        "   * After computing scores for all candidates, sort them.\n",
        "   * Keep the best `k` (e.g., 5) as your fused retrieval output.\n",
        "\n",
        "\n",
        "\n",
        "## Step 4. Build Your Evaluation Table\n",
        "\n",
        "As before, compute **Precision\\@k** and note whether the **answer is grounded**. This time evaluate both fused retrieval methods (RRF and/or weighted sum).\n",
        "\n",
        "| Query                                      | P\\@1 | P\\@3 | P\\@5 | Answer Relevant? (0/1) | Notes                                               |\n",
        "| ------------------------------------------ | ---- | ---- | ---- | ---------------------- | --------------------------------------------------- |\n",
        "| `sparse.linalg.cg`                         | 1    | 1    | 0.8  | 1                      | Found correct function signature                    |\n",
        "| `fft convolution example`                  | 1    | 0.67 | 0.8  | 1                      | Docs + code both retrieved                          |\n",
        "| *How do I solve a sparse system in SciPy?* | 1    | 0.67 | 0.8  | 1                      | Fused retrieval covered both `spsolve` and tutorial |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-H-k1Vqckl6Q",
      "metadata": {
        "id": "-H-k1Vqckl6Q"
      },
      "source": [
        "### Part 4: Sub Part 1,2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f116b4c-afa7-4cad-910f-c5c395950e13",
      "metadata": {
        "id": "9f116b4c-afa7-4cad-910f-c5c395950e13"
      },
      "outputs": [],
      "source": [
        "code_search_engine = SimilaritySearchEngine(\n",
        "    faiss_index_path=\"/content/drive/MyDrive/code/code_chunks.index\",\n",
        "    meta_data_path=\"/content/drive/MyDrive/code/chunks_metadata.json\",\n",
        "    data_type=\"code\",\n",
        "    neighbors=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "eLEiSY-XjE2A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLEiSY-XjE2A",
        "outputId": "02a78344-af0c-46e5-eb61-cea0e41e3509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       Query  Rank  SimilarityScore  \\\n",
            "0  call scipy.stats.describe     1         0.701107   \n",
            "1  call scipy.stats.describe     2         0.742446   \n",
            "2  call scipy.stats.describe     3         0.759969   \n",
            "3  call scipy.stats.describe     4         0.764987   \n",
            "4  call scipy.stats.describe     5         0.773943   \n",
            "\n",
            "                                          SourceFile  \\\n",
            "0  /content/drive/MyDrive/scipy-main/scipy/stats/...   \n",
            "1  /content/drive/MyDrive/scipy-main/scipy/stats/...   \n",
            "2  /content/drive/MyDrive/scipy-main/scipy/stats/...   \n",
            "3  /content/drive/MyDrive/scipy-main/scipy/stats/...   \n",
            "4  /content/drive/MyDrive/scipy-main/scipy/stats/...   \n",
            "\n",
            "                                             Excerpt  \n",
            "0  \"\"\" .. _statsrefmanual: ======================...  \n",
            "1  # This file is not meant for public use and wi...  \n",
            "2  # This file is not meant for public use and wi...  \n",
            "3  # This file is not meant for public use and wi...  \n",
            "4  -------- >>> import numpy as np >>> from scipy...  \n"
          ]
        }
      ],
      "source": [
        "# Run a single query\n",
        "query = \"call scipy.stats.describe\"\n",
        "results_df = code_search_engine.query(query)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "8d3533e5",
      "metadata": {
        "id": "8d3533e5"
      },
      "outputs": [],
      "source": [
        "# Pick 3-5 queries that are code-oriented\n",
        "queries = [\n",
        "    \"how to use scipy.signal.Êª§Ê≥¢\", # Code-oriented (function name with non-English characters)\n",
        "    \"error using sparse.linalg.spsolve\", # Code-oriented (error message)\n",
        "    \"how to call scipy.optimize.minimize\", # Code-oriented (\"how do I call X?\")\n",
        "    \"examples of scipy.fft usage\", # Code-oriented (examples)\n",
        "    \"understand scipy.stats.describe source code\" # Code-oriented (understanding source)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ZVblO8ZnkIdV",
      "metadata": {
        "id": "ZVblO8ZnkIdV"
      },
      "outputs": [],
      "source": [
        "for k in [1,3,5]:\n",
        "  code_search_engine = SimilaritySearchEngine(\n",
        "  faiss_index_path=\"/content/drive/MyDrive/DSF/Lab 2/code/code_chunks.index\",\n",
        "  meta_data_path=\"/content/drive/MyDrive/DSF/Lab 2/code/chunks_metadata.json\",\n",
        "  data_type=\"code\",\n",
        "  neighbors= k )\n",
        "\n",
        "  batch_results_df = code_search_engine.batch_query(queries)\n",
        "  batch_results_df.to_csv(f\"search_results_on_code_queries_with_k{k}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yEaByXjSkvrB",
      "metadata": {
        "id": "yEaByXjSkvrB"
      },
      "source": [
        "### Part 4: Sub Part 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "Dn3YkIhokVeU",
      "metadata": {
        "id": "Dn3YkIhokVeU"
      },
      "outputs": [],
      "source": [
        "docs_search_engine = SimilaritySearchEngine(\n",
        "    faiss_index_path=\"/content/drive/MyDrive/DSF/Lab 2/docs/code_chunks.index\",\n",
        "    meta_data_path=\"/content/drive/MyDrive/DSF/Lab 2/docs/chunks_metadata.json\",\n",
        "    data_type=\"docs\",\n",
        "    neighbors=50\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "pMscsiy0k2ra",
      "metadata": {
        "id": "pMscsiy0k2ra"
      },
      "outputs": [],
      "source": [
        "code_search_engine = SimilaritySearchEngine(\n",
        "  faiss_index_path=\"/content/drive/MyDrive/DSF/Lab 2/code/code_chunks.index\",\n",
        "  meta_data_path=\"/content/drive/MyDrive/DSF/Lab 2/code/chunks_metadata.json\",\n",
        "  data_type=\"code\",\n",
        "  neighbors= 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "kr8k2PqplaBb",
      "metadata": {
        "id": "kr8k2PqplaBb"
      },
      "outputs": [],
      "source": [
        "docs_df = docs_search_engine.batch_query(queries)\n",
        "docs_df.to_csv(f\"search_results_on_doc_queries_with_k{50}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "Zwt23ZaTldly",
      "metadata": {
        "id": "Zwt23ZaTldly"
      },
      "outputs": [],
      "source": [
        "code_df = code_search_engine.batch_query(queries)\n",
        "code_df.to_csv(f\"search_results_on_code_queries_with_k{50}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "ZEoal1J4lxZi",
      "metadata": {
        "id": "ZEoal1J4lxZi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class RRFFusionCalculator:\n",
        "\n",
        "    def __init__(self, k0=50):\n",
        "        self.k0 = k0\n",
        "\n",
        "    def _add_doc_results(self, docs, items, query):\n",
        "        for _, row in docs.iterrows():\n",
        "            item_id = f\"{row['SourceFile']}_{row['Rank']}\"\n",
        "            items[item_id] = {\n",
        "                \"Query\": query,\n",
        "                \"Source\": \"Docs\",\n",
        "                \"Rank\": row[\"Rank\"],\n",
        "                \"Score\": row[\"SimilarityScore\"],\n",
        "                \"File\": row[\"SourceFile\"],\n",
        "                \"Snippet\": row[\"Excerpt\"],\n",
        "                \"RRF_Score\": 1.0 / (self.k0 + row[\"Rank\"])\n",
        "            }\n",
        "\n",
        "    def _add_code_results(self, codes, items, query):\n",
        "        for _, row in codes.iterrows():\n",
        "            item_id = f\"{row['SourceFile']}_{row['Rank']}\"\n",
        "            if item_id in items:\n",
        "                items[item_id][\"RRF_Score\"] += 1.0 / (self.k0 + row[\"Rank\"])\n",
        "                items[item_id][\"Source\"] = \"Docs & Code\"\n",
        "            else:\n",
        "                items[item_id] = {\n",
        "                    \"Query\": query,\n",
        "                    \"Source\": \"Code\",\n",
        "                    \"Rank\": row[\"Rank\"],\n",
        "                    \"Score\": row[\"SimilarityScore\"],\n",
        "                    \"File\": row[\"SourceFile\"],\n",
        "                    \"Snippet\": row[\"Excerpt\"],\n",
        "                    \"RRF_Score\": 1.0 / (self.k0 + row[\"Rank\"])\n",
        "                }\n",
        "\n",
        "    def combine_results(self, docs_df, code_df, k=5):\n",
        "        \"\"\"Mix doc and code results for all queries and return top-k results.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: All combined results sorted by RRF score.\n",
        "        \"\"\"\n",
        "        all_results = []\n",
        "\n",
        "        for query in docs_df[\"Query\"].unique():\n",
        "            # Get doc and code results for this query\n",
        "            docs = docs_df[docs_df[\"Query\"] == query][[\"Rank\", \"SimilarityScore\", \"SourceFile\", \"Excerpt\"]]\n",
        "            codes = code_df[code_df[\"Query\"] == query][[\"Rank\", \"SimilarityScore\", \"SourceFile\", \"Excerpt\"]]\n",
        "\n",
        "            # Dictionary to store results and scores\n",
        "            items = {}\n",
        "\n",
        "            # Add results using separate functions\n",
        "            self._add_doc_results(docs, items, query)\n",
        "            self._add_code_results(codes, items, query)\n",
        "\n",
        "            # Turn dictionary into DataFrame, sort by score, and take top-k\n",
        "            result_df = pd.DataFrame.from_dict(items, orient=\"index\")\n",
        "            result_df = result_df.sort_values(by=\"RRF_Score\", ascending=False).head(k)\n",
        "            result_df[\"Query\"] = query\n",
        "            all_results.append(result_df[[\"Query\", \"Source\", \"Rank\", \"Score\", \"File\", \"Snippet\", \"RRF_Score\"]])\n",
        "\n",
        "        return pd.concat(all_results, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "frx2Dwujnx6e",
      "metadata": {
        "id": "frx2Dwujnx6e"
      },
      "outputs": [],
      "source": [
        "fusionCalculator = RRFFusionCalculator()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "PZMbPuARoBe-",
      "metadata": {
        "id": "PZMbPuARoBe-"
      },
      "outputs": [],
      "source": [
        "fusion_results_df = fusionCalculator.combine_results(docs_df, code_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "OslgrZQxoROy",
      "metadata": {
        "id": "OslgrZQxoROy"
      },
      "outputs": [],
      "source": [
        "fusion_results_df.to_csv('fusion_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W3sk6N_DuvKd",
      "metadata": {
        "id": "W3sk6N_DuvKd"
      },
      "source": [
        "### Part 4: Sub Part 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "sKg7G6Y_SlEO",
      "metadata": {
        "id": "sKg7G6Y_SlEO"
      },
      "outputs": [],
      "source": [
        "quantitativeQualifier = QuantitativeQualifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "s52AbCiApck4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s52AbCiApck4",
        "outputId": "430a8d99-c0c7-459b-d4f8-477460d5db30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for Precision and Recall at k=1:\n",
            "                                      Query  Precision@1  Recall@1  Relevant_Total\n",
            "          error using sparse.linalg.spsolve          0.0       0.0               0\n",
            "                examples of scipy.fft usage          1.0       1.0               1\n",
            "        how to call scipy.optimize.minimize          0.0       0.0               0\n",
            "                 how to use scipy.signal.Êª§Ê≥¢          1.0       1.0               1\n",
            "understand scipy.stats.describe source code          1.0       1.0               1\n",
            "============================================================\n",
            "Metrics for Precision and Recall at k=3:\n",
            "                                      Query  Precision@3  Recall@3  Relevant_Total\n",
            "          error using sparse.linalg.spsolve        0.000       0.0               0\n",
            "                examples of scipy.fft usage        0.667       1.0               2\n",
            "        how to call scipy.optimize.minimize        0.333       1.0               1\n",
            "                 how to use scipy.signal.Êª§Ê≥¢        1.000       1.0               3\n",
            "understand scipy.stats.describe source code        0.333       1.0               1\n",
            "============================================================\n",
            "Metrics for Precision and Recall at k=5:\n",
            "                                      Query  Precision@5  Recall@5  Relevant_Total\n",
            "          error using sparse.linalg.spsolve          0.2       1.0               1\n",
            "                examples of scipy.fft usage          0.8       1.0               4\n",
            "        how to call scipy.optimize.minimize          0.4       1.0               2\n",
            "                 how to use scipy.signal.Êª§Ê≥¢          1.0       1.0               5\n",
            "understand scipy.stats.describe source code          0.2       1.0               1\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "for i in [1,3,5]:\n",
        "    file_path = f\"code_k{i}_gpt_verification.csv\"\n",
        "    metrics_df = quantitativeQualifier.calculate_precision_recall(file_path, i)\n",
        "    print(f\"Metrics for Precision and Recall at k={i}:\")\n",
        "    print(metrics_df.to_string(index=False))\n",
        "    print('============================================================')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "a9lMWK2iSgu6",
      "metadata": {
        "id": "a9lMWK2iSgu6"
      },
      "outputs": [],
      "source": [
        "file_path = f\"fusion_results_gpt_verification.csv\"\n",
        "metrics_df = quantitativeQualifier.calculate_precision_recall(file_path, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "WfvtRRr2awaH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WfvtRRr2awaH",
        "outputId": "b2ea84ae-1f94-4dc8-8778-db2c60aa83af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"examples of scipy.fft usage\",\n          \"understand scipy.stats.describe source code\",\n          \"how to call scipy.optimize.minimize\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision@5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33466401061363027,\n        \"min\": 0.0,\n        \"max\": 0.8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8,\n          0.4,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall@5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44721359549995804,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Relevant_Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "metrics_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-16155449-3635-4410-a424-818f1a5143ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>Precision@5</th>\n",
              "      <th>Recall@5</th>\n",
              "      <th>Relevant_Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>error using sparse.linalg.spsolve</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>examples of scipy.fft usage</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how to call scipy.optimize.minimize</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how to use scipy.signal.Êª§Ê≥¢</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>understand scipy.stats.describe source code</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16155449-3635-4410-a424-818f1a5143ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16155449-3635-4410-a424-818f1a5143ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16155449-3635-4410-a424-818f1a5143ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b34160f2-7ac6-400a-894a-7cea923b8f58\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b34160f2-7ac6-400a-894a-7cea923b8f58')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b34160f2-7ac6-400a-894a-7cea923b8f58 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         Query  Precision@5  Recall@5  \\\n",
              "0            error using sparse.linalg.spsolve          0.0       0.0   \n",
              "1                  examples of scipy.fft usage          0.8       1.0   \n",
              "2          how to call scipy.optimize.minimize          0.8       1.0   \n",
              "3                   how to use scipy.signal.Êª§Ê≥¢          0.6       1.0   \n",
              "4  understand scipy.stats.describe source code          0.4       1.0   \n",
              "\n",
              "   Relevant_Total  \n",
              "0               0  \n",
              "1               4  \n",
              "2               4  \n",
              "3               3  \n",
              "4               2  "
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I34-BGz8ayfu",
      "metadata": {
        "id": "I34-BGz8ayfu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0147c5ab33514716b14628e67d99ef03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c81f7a40ee946338148841fcd1b3de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e561f961a0541abb0c89f3bb92ec685",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9ab32f6c8f8c4894b4feaa70e38955ee",
            "value": "Batches:‚Äá100%"
          }
        },
        "54c2f122ab7d4cbb9f890c1f5951b8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c81f7a40ee946338148841fcd1b3de5",
              "IPY_MODEL_982f26615d274e7fbd0b1e3fb40c0556",
              "IPY_MODEL_a7f2e707d9074c77ba174baa7ae439f6"
            ],
            "layout": "IPY_MODEL_56c25f6f5b7e406689c5018b85db20f9"
          }
        },
        "56c25f6f5b7e406689c5018b85db20f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6311df8ad0f041e2a74857147d441fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e561f961a0541abb0c89f3bb92ec685": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a436ad6acd54d3f90d6057f28b37cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "982f26615d274e7fbd0b1e3fb40c0556": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0147c5ab33514716b14628e67d99ef03",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a436ad6acd54d3f90d6057f28b37cf1",
            "value": 41
          }
        },
        "9a9a0201f92247c5a087365fb41cca7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab32f6c8f8c4894b4feaa70e38955ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7f2e707d9074c77ba174baa7ae439f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a9a0201f92247c5a087365fb41cca7a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6311df8ad0f041e2a74857147d441fce",
            "value": "‚Äá41/41‚Äá[01:19&lt;00:00,‚Äá‚Äá1.21it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
